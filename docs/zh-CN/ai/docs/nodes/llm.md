# 大模型节点（LLM）

## 是什么

大模型节点用于**调用 AI 大模型完成推理、生成或分析任务**。
你可以在这里编写提示词（Prompt），并使用流程中的变量，让模型生成你需要的结果。

这是流程中**真正“思考”和“产出内容”**的节点。

## 你可以用它做什么

#### 1. 生成文本内容

使用大模型节点，你可以让模型：

* 回答问题
* 撰写文案、总结内容
* 生成结构化文本
* 进行角色扮演式回复

例如：

* 问答助手
* 内容生成器
* 智能客服回复

---

#### 2. 理解和分析输入内容

你可以让模型对输入数据进行分析，例如：

* 理解用户意图
* 提取关键信息
* 分类、判断或评分
* 转换输入格式

---

#### 3. 使用流程变量构建动态 Prompt

在大模型节点中，你可以：

* 引用开始节点或上游节点产生的变量
* 将变量插入到 Prompt 中
* 构建动态、可复用的提示词

例如：

```text
用户问题：{{query}}
请根据以上内容给出清晰、简洁的回答。
```

## 核心配置说明

#### Prompt（提示词）

* 用自然语言描述你希望模型完成的任务
* 支持引用流程变量
* 建议清晰描述角色、目标和输出要求

---

#### 模型参数（如支持）

根据平台配置，你可能可以调整：

* 使用的模型类型
* 输出长度
* 回复风格或稳定性相关参数

这些参数会直接影响生成结果的表现。

## 输出结果

* 大模型生成的内容会作为**节点输出**
* 输出结果可以：

  * 被后续节点继续处理
  * 作为最终结果返回给用户
  * 用于条件判断或工具调用

## 使用规则

* 大模型节点必须连接在开始节点或其他节点之后
* 每次执行都会基于当前流程上下文重新生成结果
* 节点本身不保存状态，所有数据依赖流程变量

## 使用建议

* Prompt 尽量具体，避免过于模糊的指令
* 明确告诉模型你希望的**输出格式**
* 对关键流程，建议限制输出长度或结构，提升稳定性
* 将复杂任务拆分为多个大模型节点，提升可控性

## 典型场景

* 对话回复生成
* 信息总结与改写
* 结构化数据生成（如 JSON、列表）
* 多步骤推理中的核心思考节点


